{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c3d2da5b",
   "metadata": {},
   "source": [
    "## Use pipeline to find optimal model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "706400aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Filter warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import svm\n",
    "from sklearn.pipeline import Pipeline\n",
    "from tempfile import mkdtemp\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import (classification_report, confusion_matrix,\n",
    "                             plot_roc_curve, roc_auc_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "286b55f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The fitted search score is 0.8715737603942101\n",
      "The best parameters for the model are {'log__C': 1, 'reduce_dim__n_components': None}\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('../data/very_train_cleaned_airlines.csv')\n",
    "df = df.drop('Unnamed: 0', axis=1)\n",
    "df = df.drop('arrival_delay_in_minutes', axis=1)\n",
    "\n",
    "# Below I am setting our train dataset target y to 'rating'\n",
    "y = df['satisfaction_target_Satisfied']\n",
    "\n",
    "# Below I am setting our train dataset data to every column besides 'rating'\n",
    "X = df.drop('satisfaction_target_Satisfied', axis = 1)\n",
    "\n",
    "estimators = [('normalise', StandardScaler()),\n",
    "              ('reduce_dim', PCA()),\n",
    "              ('log', LogisticRegression())]\n",
    "\n",
    "cachedir = mkdtemp()\n",
    "pipe = Pipeline(estimators, memory = cachedir)\n",
    "\n",
    "params = {'log__C': [0.1, 1, 3, 5, 7, 10], \n",
    "          'reduce_dim__n_components': [None, 2, 5, 10]}\n",
    "\n",
    "grid_search = GridSearchCV(pipe, param_grid=params)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "X, y, test_size=0.3, stratify=y, random_state=0)\n",
    "\n",
    "fitted_search = grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(f\"The fitted search score is {fitted_search.score(X_test, y_test)}\")\n",
    "print(f\"The best parameters for the model are {fitted_search.best_params_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87c997e9",
   "metadata": {},
   "source": [
    "## Run code seperately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9f529985",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scaled train shape is (90916, 22) and scaled test shape is (38964, 22)\n"
     ]
    }
   ],
   "source": [
    "# scale the data\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# fit on train set\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "# use it to transform test set\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(f\"Scaled train shape is {X_train_scaled.shape} and scaled test shape is {X_test_scaled.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "babfddbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The train score is 0.8754344669805095 and the test score is 0.8715737603942101.\n"
     ]
    }
   ],
   "source": [
    "# Below I am instantiating the model\n",
    "LogReg = LogisticRegression(C=1,random_state=0)\n",
    "\n",
    "# Below I am fitting the logistic regression model to the training data\n",
    "LogReg.fit(X_train_scaled, y_train)\n",
    "\n",
    "print(f\"The train score is {LogReg.score(X_train_scaled, y_train)} and the test score is {LogReg.score(X_test_scaled, y_test)}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbcda930",
   "metadata": {},
   "source": [
    "There is a marginal amount of overfiting but both scores are similar."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f639b64",
   "metadata": {},
   "source": [
    "## Classification report & Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "02d2c4ca",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (106013668.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Input \u001b[0;32mIn [45]\u001b[0;36m\u001b[0m\n\u001b[0;31m    y_pred. = LogReg.predict(X_test_scaled)\u001b[0m\n\u001b[0m            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "y_pred. = LogReg.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ba57a761",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Classification metrics can't handle a mix of binary and multiclass-multioutput targets",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [43]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mclassification_report\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:2110\u001b[0m, in \u001b[0;36mclassification_report\u001b[0;34m(y_true, y_pred, labels, target_names, sample_weight, digits, output_dict, zero_division)\u001b[0m\n\u001b[1;32m   1998\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mclassification_report\u001b[39m(\n\u001b[1;32m   1999\u001b[0m     y_true,\n\u001b[1;32m   2000\u001b[0m     y_pred,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2007\u001b[0m     zero_division\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwarn\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   2008\u001b[0m ):\n\u001b[1;32m   2009\u001b[0m     \u001b[38;5;124;03m\"\"\"Build a text report showing the main classification metrics.\u001b[39;00m\n\u001b[1;32m   2010\u001b[0m \n\u001b[1;32m   2011\u001b[0m \u001b[38;5;124;03m    Read more in the :ref:`User Guide <classification_report>`.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2107\u001b[0m \u001b[38;5;124;03m    <BLANKLINE>\u001b[39;00m\n\u001b[1;32m   2108\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 2110\u001b[0m     y_type, y_true, y_pred \u001b[38;5;241m=\u001b[39m \u001b[43m_check_targets\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2112\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   2113\u001b[0m         labels \u001b[38;5;241m=\u001b[39m unique_labels(y_true, y_pred)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:93\u001b[0m, in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     90\u001b[0m     y_type \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulticlass\u001b[39m\u001b[38;5;124m\"\u001b[39m}\n\u001b[1;32m     92\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(y_type) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m---> 93\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m     94\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mClassification metrics can\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt handle a mix of \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m targets\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m     95\u001b[0m             type_true, type_pred\n\u001b[1;32m     96\u001b[0m         )\n\u001b[1;32m     97\u001b[0m     )\n\u001b[1;32m     99\u001b[0m \u001b[38;5;66;03m# We can't have more than one value on y_type => The set is no more needed\u001b[39;00m\n\u001b[1;32m    100\u001b[0m y_type \u001b[38;5;241m=\u001b[39m y_type\u001b[38;5;241m.\u001b[39mpop()\n",
      "\u001b[0;31mValueError\u001b[0m: Classification metrics can't handle a mix of binary and multiclass-multioutput targets"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb422605",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
